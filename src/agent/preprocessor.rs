//! Input preprocessor for multimodal content
//!
//! Handles voice and image preprocessing using Gemini Flash
//! before passing to the agent for execution.

use crate::llm::LlmClient;
use crate::sandbox::SandboxManager;
use anyhow::Result;
use std::sync::Arc;
use tracing::info;

/// Upload limit: 1 GB per session
const UPLOAD_LIMIT_BYTES: u64 = 1024 * 1024 * 1024;

/// Preprocessor for converting multimodal inputs to text
pub struct Preprocessor {
    llm_client: Arc<LlmClient>,
    user_id: i64,
}

impl Preprocessor {
    /// Create a new preprocessor with the given LLM client and user ID
    ///
    /// # Examples
    ///
    /// ```no_run
    /// use std::sync::Arc;
    /// use oxide_agent::llm::LlmClient;
    /// use oxide_agent::agent::preprocessor::Preprocessor;
    /// use oxide_agent::config::Settings;
    ///
    /// let settings = Settings::new().unwrap();
    /// let llm_client = Arc::new(LlmClient::new(&settings));
    /// let preprocessor = Preprocessor::new(llm_client, 123456789);
    /// ```
    #[must_use]
    pub const fn new(llm_client: Arc<LlmClient>, user_id: i64) -> Self {
        Self {
            llm_client,
            user_id,
        }
    }

    /// Transcribe voice audio to text using Gemini Flash
    ///
    /// Uses the existing transcription infrastructure with `OpenRouter` Gemini
    ///
    /// # Examples
    ///
    /// ```no_run
    /// # use std::sync::Arc;
    /// # use oxide_agent::llm::LlmClient;
    /// # use oxide_agent::agent::preprocessor::Preprocessor;
    /// # use oxide_agent::config::Settings;
    /// # #[tokio::main]
    /// # async fn main() -> anyhow::Result<()> {
    /// # let settings = Settings::new().unwrap();
    /// # let llm_client = Arc::new(LlmClient::new(&settings));
    /// let preprocessor = Preprocessor::new(llm_client, 123456789);
    /// let audio_bytes = vec![0; 100];
    /// let text = preprocessor.transcribe_voice(audio_bytes, "audio/ogg").await?;
    /// # Ok(())
    /// # }
    /// ```
    ///
    /// # Errors
    ///
    /// Returns an error if the transcription fails.
    pub async fn transcribe_voice(&self, audio_bytes: Vec<u8>, mime_type: &str) -> Result<String> {
        if !self.llm_client.is_multimodal_available() {
            return Err(anyhow::anyhow!("MULTIMODAL_DISABLED"));
        }

        info!(
            "Transcribing voice message: {} bytes, mime: {mime_type}",
            audio_bytes.len()
        );

        // Use Gemini Flash for transcription (via OpenRouter)
        let transcription = self
            .llm_client
            .transcribe_audio(audio_bytes, mime_type, "OR Gemini 3 Flash")
            .await
            .map_err(|e| anyhow::anyhow!("Transcription failed: {e}"))?;

        info!("Transcription result: {} chars", transcription.len());
        Ok(transcription)
    }

    /// Describe an image for the agent context
    ///
    /// Generates a detailed description that the agent can use
    ///
    /// # Examples
    ///
    /// ```no_run
    /// # use std::sync::Arc;
    /// # use oxide_agent::llm::LlmClient;
    /// # use oxide_agent::agent::preprocessor::Preprocessor;
    /// # use oxide_agent::config::Settings;
    /// # #[tokio::main]
    /// # async fn main() -> anyhow::Result<()> {
    /// # let settings = Settings::new().unwrap();
    /// # let llm_client = Arc::new(LlmClient::new(&settings));
    /// let preprocessor = Preprocessor::new(llm_client, 123456789);
    /// let image_bytes = vec![0; 100];
    /// let description = preprocessor.describe_image(image_bytes, Some("Explain this chart")).await?;
    /// # Ok(())
    /// # }
    /// ```
    ///
    /// # Errors
    ///
    /// Returns an error if the image analysis fails.
    pub async fn describe_image(
        &self,
        image_bytes: Vec<u8>,
        user_context: Option<&str>,
    ) -> Result<String> {
        if !self.llm_client.is_multimodal_available() {
            return Err(anyhow::anyhow!("MULTIMODAL_DISABLED"));
        }

        info!("Describing image: {} bytes", image_bytes.len());

        let prompt = user_context.map_or_else(
            || {
                "–û–ø–∏—à–∏ —ç—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–µ—Ç–∞–ª—å–Ω–æ –¥–ª—è AI-–∞–≥–µ–Ω—Ç–∞. \
                     –£–∫–∞–∂–∏ –≤—Å–µ –≤–∞–∂–Ω—ã–µ –¥–µ—Ç–∞–ª–∏, —Ç–µ–∫—Å—Ç, –æ–±—ä–µ–∫—Ç—ã –∏ –∏—Ö —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω–∏–µ."
                    .to_string()
            },
            |ctx| {
                format!(
                    "–û–ø–∏—à–∏ —ç—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–µ—Ç–∞–ª—å–Ω–æ –¥–ª—è AI-–∞–≥–µ–Ω—Ç–∞, –∫–æ—Ç–æ—Ä—ã–π –±—É–¥–µ—Ç –≤—ã–ø–æ–ª–Ω—è—Ç—å –∑–∞–¥–∞—á—É. \
                 –ö–æ–Ω—Ç–µ–∫—Å—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {ctx}"
                )
            },
        );

        let system_prompt = "–¢—ã - –≤–∏–∑—É–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –¥–ª—è AI-–∞–≥–µ–Ω—Ç–∞. \
                            –¢–≤–æ—è –∑–∞–¥–∞—á–∞ - —Å–æ–∑–¥–∞—Ç—å –ø–æ–¥—Ä–æ–±–Ω–æ–µ —Ç–µ–∫—Å—Ç–æ–≤–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, \
                            –∫–æ—Ç–æ—Ä–æ–µ –ø–æ–∑–≤–æ–ª–∏—Ç –∞–≥–µ–Ω—Ç—É –ø–æ–Ω—è—Ç—å –µ–≥–æ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –±–µ–∑ –¥–æ—Å—Ç—É–ø–∞ –∫ —Å–∞–º–æ–º—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é.";

        let description = self
            .llm_client
            .analyze_image(
                image_bytes,
                &prompt,
                system_prompt,
                "OR Gemini 3 Flash", // Use Gemini for multimodal
            )
            .await
            .map_err(|e| anyhow::anyhow!("Image analysis failed: {e}"))?;

        info!("Image description: {} chars", description.len());
        Ok(description)
    }

    /// Process a document uploaded by the user
    ///
    /// Uploads the file to the sandbox and returns a formatted description
    ///
    /// # Errors
    ///
    /// Returns an error if file upload fails or limit is exceeded.
    #[allow(clippy::cast_precision_loss)] // Reason: Precision loss is acceptable for display purposes in GB/MB/KB
    async fn process_document(
        &self,
        bytes: Vec<u8>,
        file_name: String,
        mime_type: Option<String>,
        caption: Option<String>,
    ) -> Result<String> {
        let upload_path = format!("/workspace/uploads/{}", Self::sanitize_filename(&file_name));

        // Lazy-create sandbox
        let mut manager = SandboxManager::new(self.user_id).await?;
        if !manager.is_running() {
            manager.create_sandbox().await?;
        }

        // Check upload limit
        let current_size = manager.get_uploads_size().await.unwrap_or(0);
        let new_size = current_size + bytes.len() as u64;

        if new_size > UPLOAD_LIMIT_BYTES {
            anyhow::bail!(
                "–ü—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç –∑–∞–≥—Ä—É–∑–∫–∏: {:.1} GB / 1 GB. –ü–µ—Ä–µ—Å–æ–∑–¥–∞–π—Ç–µ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä.",
                new_size as f64 / 1024.0 / 1024.0 / 1024.0
            );
        }

        manager.upload_file(&upload_path, &bytes).await?;

        let size_str = Self::format_file_size(bytes.len());
        let hint = Self::get_file_type_hint(&file_name);

        let mut parts = vec![
            "üìé **–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –∑–∞–≥—Ä—É–∑–∏–ª —Ñ–∞–π–ª:**".to_string(),
            format!("   –ü—É—Ç—å: `{}`", upload_path),
            format!("   –†–∞–∑–º–µ—Ä: {}", size_str),
        ];

        if let Some(mime_type) = &mime_type {
            parts.push(format!("   –¢–∏–ø: {mime_type}"));
        }

        parts.push(String::new());
        parts.push(hint);

        parts.push(String::new());
        if let Some(caption) = caption {
            parts.push(format!("**–°–æ–æ–±—â–µ–Ω–∏–µ:** {caption}"));
        } else {
            parts.push("_–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–µ –æ—Å—Ç–∞–≤–∏–ª –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π._".to_string());
        }

        Ok(parts.join("\n"))
    }

    /// Sanitize a filename by replacing dangerous characters
    #[must_use]
    fn sanitize_filename(name: &str) -> String {
        // Manually extract file name handling both / and \ as separators
        // This is necessary because Path::new uses OS-specific separators,
        // but we might receive paths from different OSs (e.g. Windows path on Linux container)
        let name = name.rsplit(['/', '\\']).next().unwrap_or(name);

        let name = if name.is_empty() { "file" } else { name };

        name.chars()
            .map(|c| match c {
                '/' | '\\' | '\0' | ':' | '*' | '?' | '"' | '<' | '>' | '|' | ' ' => '_',
                _ => c,
            })
            .collect()
    }

    /// Format file size in human-readable format
    #[must_use]
    #[allow(clippy::cast_precision_loss)] // Reason: Precision loss is acceptable for human-readable file sizes
    fn format_file_size(bytes: usize) -> String {
        const KB: usize = 1024;
        const MB: usize = KB * 1024;

        if bytes >= MB {
            format!("{:.1} MB", bytes as f64 / MB as f64)
        } else if bytes >= KB {
            format!("{:.1} KB", bytes as f64 / KB as f64)
        } else {
            format!("{bytes} B")
        }
    }

    /// Get a hint about how to handle the file based on its extension
    #[must_use]
    fn get_file_type_hint(file_name: &str) -> String {
        let ext = std::path::Path::new(file_name)
            .extension()
            .map(|e| e.to_string_lossy().to_lowercase());

        match ext.as_deref() {
            Some("py" | "rs" | "js" | "ts" | "go" | "java" | "cpp" | "c" | "h") => {
                "üí° –ò—Å—Ö–æ–¥–Ω—ã–π –∫–æ–¥. –ò—Å–ø–æ–ª—å–∑—É–π `read_file` –∏–ª–∏ –≤—ã–ø–æ–ª–Ω–∏.".into()
            }
            Some("json" | "yaml" | "yml" | "toml" | "xml") => {
                "üí° –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ. –ß–∏—Ç–∞–π —á–µ—Ä–µ–∑ `read_file`.".into()
            }
            Some("csv") => "üí° CSV. –û–±—Ä–∞–±–æ—Ç–∞–π —á–µ—Ä–µ–∑ Python pandas.".into(),
            Some("xlsx" | "xls") => "üí° Excel. –ò—Å–ø–æ–ª—å–∑—É–π Python openpyxl/pandas.".into(),
            Some("zip" | "tar" | "gz" | "7z" | "rar") => {
                "üí° –ê—Ä—Ö–∏–≤. –†–∞—Å–ø–∞–∫—É–π: `unzip`, `tar -xf`, etc.".into()
            }
            Some("png" | "jpg" | "jpeg" | "gif" | "webp" | "svg") => {
                "üí° –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ. –û–±—Ä–∞–±–æ—Ç–∞–π —á–µ—Ä–µ–∑ Python PIL.".into()
            }
            Some("txt" | "md" | "log" | "ini" | "cfg") => {
                "üí° –¢–µ–∫—Å—Ç. –ß–∏—Ç–∞–π —á–µ—Ä–µ–∑ `read_file`.".into()
            }
            Some("pdf") => "üí° PDF. –ò—Å–ø–æ–ª—å–∑—É–π Python PyPDF2/pdfplumber.".into(),
            Some("sql" | "db" | "sqlite") => "üí° –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö. –ò—Å–ø–æ–ª—å–∑—É–π Python sqlite3.".into(),
            _ => "üí° –ò—Å–ø–æ–ª—å–∑—É–π –ø–æ–¥—Ö–æ–¥—è—â–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã.".into(),
        }
    }

    /// Preprocess any input type and return text suitable for the agent
    ///
    /// # Examples
    ///
    /// ```no_run
    /// # use std::sync::Arc;
    /// # use oxide_agent::llm::LlmClient;
    /// # use oxide_agent::agent::preprocessor::{Preprocessor, AgentInput};
    /// # use oxide_agent::config::Settings;
    /// # #[tokio::main]
    /// # async fn main() -> anyhow::Result<()> {
    /// # let settings = Settings::new().unwrap();
    /// # let llm_client = Arc::new(LlmClient::new(&settings));
    /// let preprocessor = Preprocessor::new(llm_client, 123456789);
    /// let input = AgentInput::Text("Hello".to_string());
    /// let result = preprocessor.preprocess_input(input).await?;
    /// assert_eq!(result, "Hello");
    /// # Ok(())
    /// # }
    /// ```
    ///
    /// # Errors
    ///
    /// Returns an error if transcription or image analysis fails.
    pub async fn preprocess_input(&self, input: AgentInput) -> Result<String> {
        match input {
            AgentInput::Text(text) => Ok(text),
            AgentInput::Voice { bytes, mime_type } => {
                self.transcribe_voice(bytes, &mime_type).await
            }
            AgentInput::Image { bytes, context } => {
                self.describe_image(bytes, context.as_deref()).await
            }
            AgentInput::ImageWithText { image_bytes, text } => {
                let description = self.describe_image(image_bytes, Some(&text)).await?;
                Ok(format!(
                    "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –æ—Ç–ø—Ä–∞–≤–∏–ª –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å —Ç–µ–∫—Å—Ç–æ–º: \"{text}\"\n\n–û–ø–∏—Å–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:\n{description}"
                ))
            }
            AgentInput::Document {
                bytes,
                file_name,
                mime_type,
                caption,
            } => {
                self.process_document(bytes, file_name, mime_type, caption)
                    .await
            }
        }
    }
}

/// Types of input the agent can receive
pub enum AgentInput {
    /// Plain text message
    Text(String),
    /// Voice message to be transcribed
    Voice {
        /// Raw audio bytes
        bytes: Vec<u8>,
        /// MIME type of the audio
        mime_type: String,
    },
    /// Image to be described
    Image {
        /// Raw image bytes
        bytes: Vec<u8>,
        /// Optional context from the user (caption)
        context: Option<String>,
    },
    /// Image with accompanying text
    ImageWithText {
        /// Raw image bytes
        image_bytes: Vec<u8>,
        /// Accompanying text
        text: String,
    },
    /// Document uploaded by user
    Document {
        /// Raw file bytes
        bytes: Vec<u8>,
        /// Original filename
        file_name: String,
        /// MIME type of the file
        mime_type: Option<String>,
        /// Optional caption from the user
        caption: Option<String>,
    },
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_sanitize_filename_basic() {
        assert_eq!(Preprocessor::sanitize_filename("file.txt"), "file.txt");
        assert_eq!(
            Preprocessor::sanitize_filename("my file.txt"),
            "my_file.txt"
        );
    }

    #[test]
    fn test_sanitize_filename_path_traversal() {
        assert_eq!(
            Preprocessor::sanitize_filename("../../../etc/passwd"),
            "passwd"
        );
        assert_eq!(Preprocessor::sanitize_filename("/etc/passwd"), "passwd");
        assert_eq!(
            Preprocessor::sanitize_filename("..\\..\\windows\\system32"),
            "system32"
        );
    }

    #[test]
    fn test_sanitize_filename_special_chars() {
        assert_eq!(
            Preprocessor::sanitize_filename("file:name?.txt"),
            "file_name_.txt"
        );
        assert_eq!(
            Preprocessor::sanitize_filename("test<>|file"),
            "test___file"
        );
    }

    #[test]
    fn test_sanitize_empty_filename() {
        // Empty name should become "file"
        assert_eq!(Preprocessor::sanitize_filename(""), "file");
    }

    #[test]
    fn test_sanitize_only_extension() {
        assert_eq!(Preprocessor::sanitize_filename(".gitignore"), ".gitignore");
    }

    #[test]
    fn test_format_file_size() {
        assert_eq!(Preprocessor::format_file_size(500), "500 B");
        assert_eq!(Preprocessor::format_file_size(1_024), "1.0 KB");
        assert_eq!(Preprocessor::format_file_size(1_536), "1.5 KB");
        assert_eq!(Preprocessor::format_file_size(1_048_576), "1.0 MB");
        assert_eq!(Preprocessor::format_file_size(1_572_864), "1.5 MB");
    }

    #[test]
    fn test_format_file_size_zero() {
        assert_eq!(Preprocessor::format_file_size(0), "0 B");
    }

    #[test]
    fn test_format_file_size_large() {
        // 1 GB
        assert_eq!(Preprocessor::format_file_size(1_073_741_824), "1024.0 MB");
    }

    #[test]
    fn test_get_file_type_hint() {
        assert!(Preprocessor::get_file_type_hint("script.py").contains("–∫–æ–¥"));
        assert!(Preprocessor::get_file_type_hint("data.csv").contains("pandas"));
        assert!(Preprocessor::get_file_type_hint("archive.zip").contains("–ê—Ä—Ö–∏–≤"));
        assert!(Preprocessor::get_file_type_hint("image.png").contains("PIL"));
        assert!(Preprocessor::get_file_type_hint("unknown.xyz").contains("–∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã"));
    }
}
