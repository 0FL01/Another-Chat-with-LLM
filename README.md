# Another Chat TG Bot (Rust)

Универсальный Telegram-бот с ИИ-ассистентом, поддерживающий множество моделей, типы контента и расширенные функции. **Написан на Rust.**

## Описание

Этот проект представляет собой Telegram-бота, который интегрируется с различными API больших языковых моделей (LLM) для предоставления пользователям многофункционального ИИ-ассистента. Бот может обрабатывать текстовые, голосовые, видео сообщения и изображения, работать с документами различных форматов, управлять историей диалога и предоставлять административные функции для управления доступом пользователей.

Бот разработан с использованием **Rust**, библиотеки `teloxide`, `rusoto_s3` для взаимодействия с Cloudflare R2, и SDK для работы с ИИ-моделями (Groq, Mistral AI, Google Gemini, OpenRouter). Развертывание осуществляется с помощью Docker.

## Возможности

*   **Поддержка множества LLM:** Интеграция с моделями от Groq, Mistral AI, Google Gemini, OpenRouter (доступ к 200+ моделям через единый API).
*   **Обработка различных типов ввода:**
    *   Текстовые сообщения.
    *   Голосовые сообщения (распознавание речи через Gemini).
    *   Видео сообщения (извлечение аудио и распознавание через Gemini).
    *   Изображения (анализ и описание через ИИ-модели).
*   **Управление контекстом:**
    *   Сохранение истории диалога в Cloudflare R2 (S3-совместимое хранилище).
    *   Возможность очистки контекста диалога.
*   **Гибкость моделей:** Пользователи могут переключаться между доступными моделями.
*   **Персонализация:**
    *   Поддержка пользовательских системных промптов.
    *   Сохранение предпочитаемой модели для каждого пользователя.
*   **Авторизация:**
    *   Доступ к боту только для разрешенных пользователей (указываются в `.env`).
*   **Форматирование ответов:** Поддержка Markdown/HTML разметки Telegram (жирный шрифт, курсив, блоки кода, списки).
*   **Обработка длинных сообщений:** Автоматическое разделение длинных ответов на несколько сообщений.
*   **Развертывание с Docker:** Легкое развертывание с использованием Docker.
*   **Логирование:** Подробное логирование с маскированием чувствительных данных (токены, данные БД).
*   **Высокая производительность:** Rust обеспечивает низкое потребление памяти и быструю обработку запросов.

## Необходимые условия

*   **Docker:** [Установите Docker](https://docs.docker.com/engine/install/)
*   **Git:** Для клонирования репозитория.
*   **Cloudflare R2:** Бакет для хранения данных пользователей и истории.
*   **API Ключи:** Получите необходимые API ключи для сервисов, которые планируете использовать (см. раздел Конфигурация).

## Установка и запуск

1.  **Клонируйте репозиторий:**
    ```bash
    git clone https://github.com/0FL01/Another-Chat-with-LLM.git
    cd Another-Chat-with-LLM
    ```

2.  **Создайте файл `.env`:**
    Создайте файл `.env` в корневой директории проекта и заполните его необходимыми переменными окружения. Скопируйте структуру из примера ниже.

3.  **Настройте Cloudflare R2:**
    Убедитесь, что у вас создан бакет в Cloudflare R2 и получены Access Key ID, Secret Access Key и Endpoint URL. Укажите эти данные в `.env`. Бот автоматически начнет использовать бакет для хранения данных.

4.  **Соберите и запустите контейнер:**
    ```bash
    docker-compose up --build -d
    ```
    Эта команда соберет Docker образ и запустит контейнер в фоновом режиме (`-d`).

## Конфигурация

Создайте файл `.env` в корневой директории проекта и добавьте следующие переменные:

```dotenv
# Telegram
TELEGRAM_TOKEN=ВАШ_ТЕЛЕГРАМ_БОТ_ТОКЕН
ALLOWED_USERS=123456789,987654321

# Cloudflare R2
R2_ACCESS_KEY_ID=ваш_access_key_id
R2_SECRET_ACCESS_KEY=ваш_secret_access_key
R2_ENDPOINT_URL=https://<account_id>.r2.cloudflarestorage.com
R2_BUCKET_NAME=имя_вашего_бакета

# API Keys (укажите те, которые будете использовать)
GROQ_API_KEY=ВАШ_GROQ_API_КЛЮЧ
MISTRAL_API_KEY=ВАШ_MISTRAL_API_КЛЮЧ
GEMINI_API_KEY=ВАШ_GEMINI_API_КЛЮЧ # Необходим для транскрипции аудио/видео и моделей Gemini
OPENROUTER_API_KEY=ВАШ_OPENROUTER_API_КЛЮЧ # Для доступа к моделям через OpenRouter (по умолчанию)

# Опциональные настройки OpenRouter
# OPENROUTER_SITE_URL="https://your-site.com" # URL вашего сайта для рейтинга на openrouter.ai
# OPENROUTER_SITE_NAME="My Bot Name" # Название вашего бота для рейтинга на openrouter.ai

# Опциональные настройки промптов
# SYSTEM_MESSAGE="Ваш кастомный системный промпт по умолчанию"
```

**Важно:**
*   Замените `ВАШ_*` на ваши реальные токены, ID и учетные данные.
*   `ALLOWED_USERS` - это список Telegram ID пользователей через запятую, которые будут иметь доступ к боту.
*   Для работы с Cloudflare R2 убедитесь, что ваш бакет публично доступен (если требуется) или вы используете корректные S3-совместимые ключи.

## Использование

1.  **Найдите вашего бота в Telegram** по имени пользователя, которое вы указали при создании бота.
2.  **Отправьте команду `/start`**. Если ваш Telegram ID добавлен в `ALLOWED_USERS` в `.env`, бот вас поприветствует.
3.  **Начните общение:** Отправляйте текстовые сообщения, голосовые сообщения, видео, изображения.
4.  **Используйте клавиатуру:**
    *   **"Очистить контекст"**: Удаляет историю текущего диалога для вас.
    *   **"Сменить модель"**: Позволяет выбрать другую доступную ИИ-модель для генерации ответов.
    *   **"Доп функции"**: Открывает меню с дополнительными опциями.
        *   **"Изменить промпт"**: Позволяет установить кастомный системный промпт для ваших диалогов.
        *   **"Назад"**: Возврат в главное меню.

## Доступные модели

*   **OR Gemini 3 Flash** (OpenRouter, модель по умолчанию) - мультимодальная модель с поддержкой изображений, аудио и видео
*   **Gemini 2.5 Flash Lite** (Google AI)
*   **GPT-OSS-120b** (Groq)
*   **Mistral Large** (Mistral AI)

*(Список моделей и их параметры определены в `rust-src/src/config.rs`)*

### Мультимодальность через OpenRouter

При использовании модели OpenRouter (OR Gemini 3 Flash) бот поддерживает мультимодальные входные данные:
*   **Изображения** - анализ и описание изображений
*   **Аудио** - транскрипция голосовых сообщений
*   **Видео** - извлечение и транскрипция аудиодорожки из видео

Эти возможности реализованы с автоматическими ретраями и fallback на резервную модель для надёжности работы.

## Развертывание

Проект использует Docker для упрощения развертывания.

*   `Dockerfile` описывает сборку Rust приложения с использованием multi-stage build.
*   `docker-compose.yml` определяет сервис `another_chat_tg`, который запускает контейнер:
    *   Использует `network_mode: "host"` для прямого доступа к сетевому интерфейсу хоста.
    *   Передает переменные окружения через `env_file`.
    *   Устанавливает политику перезапуска `unless-stopped`.

## Структура проекта

```
.
├── rust-src/              # Исходный код на Rust
│   ├── src/
│   │   ├── main.rs        # Точка входа приложения
│   │   ├── bot/           # Логика Telegram бота
│   │   ├── llm/           # LLM клиенты (Groq, Mistral, Gemini, OpenRouter)
│   │   ├── storage.rs     # Работа с Cloudflare R2
│   │   ├── config.rs      # Конфигурация
│   │   └── utils.rs       # Вспомогательные функции
│   └── Cargo.toml         # Rust зависимости
├── Dockerfile             # Конфигурация Docker образа
├── docker-compose.yml     # Конфигурация Docker Compose
├── .env.example           # Пример переменных окружения
└── README.md              # Этот файл
```

## Разработка

Для локальной разработки без Docker:

1. **Установите Rust:**
   ```bash
   curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh
   ```

2. **Запуск:**
   ```bash
   cd rust-src
   cargo run
   ```

3. **Тесты:**
   ```bash
   cargo test
   ```

4. **Линтинг:**
   ```bash
   cargo clippy
   ```

## Python версия

Оригинальная версия на Python доступна в ветке [`python`](https://github.com/0FL01/Another-Chat-with-LLM/tree/python).

## Лицензия

MIT License
